
# üìä Proyecto 8: Predicci√≥n de empleados

## üìñ Descripci√≥n del Proyecto

Este proyecto aborda uno de los mayores retos de Recursos Humanos: la rotaci√≥n de empleados. La pregunta central es: ¬øqu√© factores influyen en que un empleado decida quedarse o irse de la empresa? Para responder a esta pregunta, hemos utilizado datos ficticios de encuestas, m√©tricas de desempe√±o y otras caracter√≠sticas de los empleados para desarrollar un modelo predictivo que determine la probabilidad de que un empleado se vaya.

El an√°lisis va m√°s all√° de los n√∫meros y se enfoca en comprender el impacto de las decisiones empresariales en la vida de las personas, proponiendo mejoras que podr√≠an ayudar a las empresas a ser mejores lugares de trabajo.

## üéØ Objetivos del proyecto

- Construir un modelo de machine learning que prediga la retenci√≥n o rotaci√≥n de los empleados.
- Identificar los factores m√°s relevantes que influyen en la decisi√≥n de un empleado de quedarse o irse.
- Proponer estrategias y recomendaciones basadas en los resultados del modelo para mejorar la retenci√≥n de empleados.

## üóÇÔ∏è Estructura del Proyecto

El proyecto est√° organizado de la siguiente manera:

```bash
‚îú‚îÄ‚îÄ datos/                # Conjuntos de datos sin procesar y ya procesados
‚îÇ   ‚îú‚îÄ‚îÄ output/           # Datos procesados y resultados finales
‚îÇ   ‚îî‚îÄ‚îÄ raw/              # Datos en bruto (sin procesar)
‚îÇ
‚îú‚îÄ‚îÄ flask/                # Archivos relacionados con el despliegue en Flask
‚îÇ
‚îú‚îÄ‚îÄ modelos/              # Modelos predictivos
‚îÇ
‚îú‚îÄ‚îÄ notebooks/            # Notebooks con el contenido y an√°lisis de datos
‚îÇ
‚îú‚îÄ‚îÄ src/                  # Scripts para la limpieza y procesamiento de datos
‚îÇ
‚îú‚îÄ‚îÄ streamlit/            # Archivos relacionados con la aplicaci√≥n en Streamlit
‚îÇ
‚îú‚îÄ‚îÄ README.md             # Descripci√≥n general del proyecto e instrucciones
‚îî‚îÄ‚îÄ requirements.txt      # Lista de dependencias del proyecto
```

## üõ†Ô∏è Instalaci√≥n y Requisitos

Este proyecto utiliza [Python 3.12](https://docs.python.org/3.12/) y requiere las siguientes bibliotecas para la ejecuci√≥n y an√°lisis:

- [pandas 2.2.3](https://pandas.pydata.org/docs/)
- [matplotlib 3.9.2](https://matplotlib.org/stable/index.html)
- [seaborn 0.13.2](https://seaborn.pydata.org/tutorial.html)
- [scikit-learn 1.5.2](https://scikit-learn.org/stable/)
- [imbalanced-learn 0.12.4](https://imbalanced-learn.org/stable/)
- [streamlit 1.40.2](https://docs.streamlit.io/)
- [Flask 3.1.0](https://flask.palletsprojects.com/)

Para instalar las dependencias, puedes ejecutar el siguiente comando dentro de un entorno virtual:

```bash
pip install -r requirements.txt
```

## üìä Resultados y Conclusiones

### Resumen de Conclusiones con M√©tricas Espec√≠ficas

A lo largo del an√°lisis se evaluaron distintos modelos predictivos y se compararon utilizando m√©tricas de rendimiento como `accuracy`, `precision`, `recall`, `f1`, `kappa` y `auc`. A continuaci√≥n, se presentan las conclusiones de cada conjunto de m√©tricas evaluadas, acompa√±adas de un breve resumen de los resultados obtenidos:

1. **Primera Evaluaci√≥n**

   ![M√©tricas Evaluaci√≥n 1](assets/image-1.png)

   - **Logistic Regression**: Obtuvo una `accuracy` de **85.13%** en el conjunto de entrenamiento y de **84.49%** en el conjunto de prueba. Esto indica un rendimiento aceptable, pero con m√©tricas `kappa` bajas (**0.029** en entrenamiento y **-0.011** en prueba), lo cual sugiere una capacidad limitada para diferenciar entre las clases correctamente.
   - **√Årbol de Decisi√≥n**: Obtuvo una `accuracy` de **97.76%** en el conjunto de entrenamiento y **94.51%** en prueba. Sin embargo, la ca√≠da en `kappa` de **0.905** a **0.765** indica cierto nivel de sobreajuste.
   - **Random Forest**: Present√≥ un rendimiento muy alto con una `accuracy` de **99.28%** en el conjunto de prueba y un valor de `kappa` de **0.972**, indicando un excelente equilibrio y capacidad de generalizaci√≥n.
   - **Gradient Boosting y XGBoost**: Ambos modelos alcanzaron una `accuracy` perfecta en el entrenamiento y de **99.28%** en el conjunto de prueba, lo cual muestra un gran rendimiento, aunque debe validarse la posible existencia de sobreajuste.


2. **Segunda Evaluaci√≥n**

   ![M√©tricas Evaluaci√≥n 2](assets/image-2.png)

   - **Logistic Regression**: La `accuracy` mejor√≥ ligeramente en el conjunto de prueba (**77.88%**), mientras que el valor de `kappa` tambi√©n mostr√≥ una mejora (**0.567**). Esto sugiere una ligera mejora en la capacidad del modelo para identificar correctamente las clases.
   - **√Årbol de Decisi√≥n**: Obtuvo una `accuracy` de **96.30%** en entrenamiento y **94.56%** en prueba. El valor de `kappa` fue de **0.925** en entrenamiento y **0.891** en prueba, indicando una ligera mejora en comparaci√≥n con la primera evaluaci√≥n, pero a√∫n existe sobreajuste.
   - **Random Forest**: Mantiene un rendimiento excelente con `accuracy` de **100%** en entrenamiento y prueba. Los valores de `kappa` tambi√©n alcanzaron **1.0**, indicando una muy buena capacidad para generalizar.
   - **Gradient Boosting y XGBoost**: Ambos modelos mantienen un rendimiento perfecto con `accuracy` de **100%** en entrenamiento y de **99.80%** en el conjunto de prueba. Los valores de `kappa` tambi√©n son muy altos (**0.996**), lo cual reafirma la capacidad de generalizaci√≥n.


3. **Tercera Evaluaci√≥n**

   ![M√©tricas Evaluaci√≥n 3](assets/image-3.png)

   - **√Årbol de Decisi√≥n**: `Accuracy` de **95.27%**, `kappa` de **0.9055**, y `AUC` de **0.9806**.
    - **Random Forest**: Obtuvo `accuracy` de **100%** y `kappa` de **1.0**, indicando una excelente capacidad de generalizaci√≥n. El tiempo de c√≥mputo fue eficiente (**0.0256** segundos), incluso sin paralelismo.
    - **Gradient Boosting**: Rendimiento casi perfecto con `accuracy` de **100%** y `kappa` de **1.0**. Utiliz√≥ **16 n√∫cleos** para un tiempo de c√≥mputo r√°pido (**0.0168** segundos).
    - **XGBoost**: `Accuracy` de **100%** en entrenamiento y **99.93%** en prueba, con `kappa` de **0.9987**. Mostr√≥ alta eficiencia con un tiempo de c√≥mputo bajo (**0.0183** segundos).

4. **Cuarta Evaluaci√≥n**

    ![M√©tricas Evaluaci√≥n 4](assets/image-4.png)

    - **Random Forest**: `Accuracy` de **100%**, `kappa` de **1.0**, y `AUC` de **1.0**. El modelo tuvo una predicci√≥n perfecta tanto en entrenamiento como en prueba, mostrando una alta capacidad de generalizaci√≥n. El tiempo de c√≥mputo fue bajo (**0.0244** segundos), sin el uso de m√∫ltiples n√∫cleos.
    - **Gradient Boosting**: `Accuracy` de **100%** y `kappa` de **1.0**, con un `AUC` de **1.0**. Utiliz√≥ **16 n√∫cleos** para un tiempo de c√≥mputo eficiente (**0.0110** segundos), demostrando una excelente capacidad de generalizaci√≥n y eficiencia.
    - **XGBoost**: `Accuracy` de **100%** en entrenamiento y **93.75%** en prueba, con `kappa` de **0.875**. Aunque mostr√≥ una ligera disminuci√≥n en precisi√≥n durante la prueba, se mantuvo eficiente con un tiempo de c√≥mputo bajo (**0.0165** segundos).

5. **Quinta Evaluaci√≥n**

    ![M√©tricas Evaluaci√≥n 5](assets/image-5.png)
    
    - **Random Forest**: `Accuracy` de **92.68%**, `kappa` de **0.8536**, y `AUC` de **0.9841**. Este modelo tuvo un buen rendimiento con una alta capacidad de generalizaci√≥n, reflejada en un valor de `kappa` s√≥lido y un `AUC` elevado. El tiempo de c√≥mputo fue de **0.0422** segundos, sin el uso de m√∫ltiples n√∫cleos, mostrando una eficiencia razonable.
    - **Gradient Boosting**: `Accuracy` de **100%**, `kappa` de **1.0**, y `AUC` de **1.0**. Utiliz√≥ **16 n√∫cleos** para un tiempo de c√≥mputo eficiente (**0.0105** segundos), indicando un excelente rendimiento tanto en precisi√≥n como en eficiencia.
    - **XGBoost**: `Accuracy` de **92.49%** en entrenamiento y prueba, con `kappa` de **0.8499**. Mantuvo un buen equilibrio entre precisi√≥n y eficiencia, con un tiempo de c√≥mputo bajo (**0.0187** segundos).


### Resumen General de Resultados

- **Modelos de Ensamble** como **Random Forest**, **Gradient Boosting** y **XGBoost** obtuvieron los mejores resultados, con `accuracy` en el conjunto de prueba superior al **92%**, indicando una capacidad de predicci√≥n robusta.
- **Regresi√≥n Log√≠stica** mostr√≥ un rendimiento constante, aunque limitado en comparaci√≥n con los modelos m√°s complejos, con `accuracy` en torno al **75-80%**.
- **√Årbol de Decisi√≥n** presenta cierta tendencia al sobreajuste, con buenos resultados en el entrenamiento, pero una ca√≠da notable en el conjunto de prueba.

## üîÑ Pr√≥ximos Pasos

- Implementar un sistema de monitoreo en la empresa que permita recopilar datos en tiempo real sobre la satisfacci√≥n y desempe√±o de los empleados para ajustar el modelo con datos actualizados.
- Probar t√©cnicas de ensamblaje para combinar varios modelos y mejorar la precisi√≥n de las predicciones.

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Si deseas colaborar en este proyecto, por favor abre un pull request o una issue en este repositorio.

## ‚úíÔ∏è Autores

Iv√°n Bravo - Autor principal del proyecto.